# Network
MODEL_USE: mfh
HIGH_ORDER: True #True for MFH, False for MFB
HIDDEN_SIZE: 512
IMAGE_CHANNEL: 2048
MFB_FACTOR_NUM: 5
MFB_OUT_SIZE: 1000
LSTM_OUT_SIZE: 1024
LSTM_DROPOUT_RATIO: 0.1
MFB_DROPOUT_RATIO: 0.1
MAX_WORDS_IN_QUESTION: 15
NUM_IMG_GLIMPSES: 2
NUM_QUES_GLIMPSES: 2
EMBEDDING_SIZE: 300
IMG_FEAT_SIZE: 100

# Execution
BATCH_SIZE: 64
VAL_BATCH_SIZE: 32
LR_BASE: 0.0007
LR_DECAY_R: 0.25
LR_DECAY_LIST: [6, 12]
WARMUP_EPOCH: 0
MAX_EPOCH: 13
GRAD_NORM_CLIP: -1
GRAD_ACCU_STEPS: 1
LOSS_FUNC: kld
LOSS_REDUCTION: sum
OPT: Adam
OPT_PARAMS: {betas: '(0.9, 0.99)', eps: '1e-9'}
